{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Logistic Regression\n",
    "This Notebook contains the optimized Logistic Regression with the 51 selected features. A logistic regression was choosen, because it is the model _Die Zeit_ uses and we tried to beat. Therefore we wanted to see if we could allready beat the model with our engineered and selecte features, as well as tuning. Furthermore, when working with our data that accumulates to a binary separation, we want to classify our observations as the customer “will churn” or “won’t churn”. A logistic Regression determines the probability of belonging in one or the other group. The model predicts relationships between the target feature churn and the remaining features to apply probabilistic calculations for determining which class the customer should belong to. Threfore we see a Logistic regression a good fit to predict customer churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# own modules\n",
    "import eda_methods as eda\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")  \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# warnings handler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import fbeta_score, accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "random_state=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "\n",
    "def train_predict(modelname, y_train, y_test, predictions_train, predictions_test):\n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       -\n",
    "       - y_train: income training set\n",
    "       -\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    # model name\n",
    "    results['model'] = modelname\n",
    "    # accuracy\n",
    "    results['acc_train'] = accuracy_score(y_train,predictions_train)\n",
    "    results['acc_test'] = accuracy_score(y_test,predictions_test)\n",
    "    # F-score\n",
    "    #results[‘f_train’] = fbeta_score(y_train,predictions_train,0.5)\n",
    "    #results[‘f_test’] = fbeta_score(y_test,predictions_test,0.5)\n",
    "    # F1-score\n",
    "    results['f1_train'] = f1_score(y_train,predictions_train)\n",
    "    results['f1_test'] = f1_score(y_test,predictions_test)\n",
    "    # Recall\n",
    "    results['recall_train'] = recall_score(y_train,predictions_train)\n",
    "    results['recall_test'] = recall_score(y_test,predictions_test)\n",
    "    # Precision\n",
    "    results['precision_train'] = precision_score(y_train,predictions_train)\n",
    "    results['precision_test'] = precision_score(y_test,predictions_test)\n",
    "    #fbets\n",
    "    results['fbeta_train'] = fbeta_score(y_train, predictions_train, beta = .5, average = 'weighted').round(2)\n",
    "    results['fbeta_test'] =fbeta_score(y_test, predictions_test, beta = .5, average = 'weighted').round(2)\n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new feature dataframe\n",
    "df = pd.read_csv('data/df_clean_engineered_all.csv')\n",
    "y = df['churn']\n",
    "# Drop some obvious unnecessary features\n",
    "df = df.drop(['churn','plz_3','abo_registrierung_min','nl_registrierung_min','ort'], axis = 1)\n",
    "# Get dummies for the categorial features\n",
    "df = pd.get_dummies(df, columns = ['kanal', 'objekt_name', 'aboform_name', 'zahlung_rhythmus_name',\n",
    "                                   'zahlung_weg_name', 'plz_1', 'plz_2', 'land_iso_code', \n",
    "                                   'anrede','titel'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184660, 307)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184660, 51)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 51 selected features \n",
    "X = df[['zahlung_weg_name_Rechnung',\n",
    " 'zahlung_rhythmus_name_halbjährlich',\n",
    " 'rechnungsmonat',\n",
    " 'received_anzahl_6m',\n",
    " 'openedanzahl_6m',\n",
    " 'objekt_name_ZEIT Digital',\n",
    " 'nl_zeitbrief',\n",
    " 'nl_aktivitaet',\n",
    " 'liefer_beginn_evt',\n",
    " 'cnt_umwandlungsstatus2_dkey',\n",
    " 'clickrate_3m',\n",
    " 'anrede_Frau',\n",
    " 'aboform_name_Geschenkabo',\n",
    " 'unsubscribed_anzahl_1m',\n",
    " 'studentenabo',\n",
    " 'received_anzahl_bestandskunden_6m',\n",
    " 'openrate_produktnews_3m',\n",
    " 'opened_anzahl_bestandskunden_6m',\n",
    " 'objekt_name_DIE ZEIT - CHRIST & WELT',\n",
    " 'nl_zeitshop',\n",
    " 'nl_opt_in_sum',\n",
    " 'nl_opened_1m',\n",
    " 'kanal_andere',\n",
    " 'kanal_B2B',\n",
    " 'clicked_anzahl_6m',\n",
    " 'che_reg',\n",
    " 'MONTH_DELTA_nl_min',\n",
    " 'zon_zp_red',\n",
    " 'zahlung_rhythmus_name_vierteljährlich',\n",
    " 'unsubscribed_anzahl_hamburg_1m',\n",
    " 'unsubscribed_anzahl_6m',\n",
    " 'sum_zon',\n",
    " 'sum_reg',\n",
    " 'shop_kauf',\n",
    " 'plz_2_10',\n",
    " 'plz_1_7',\n",
    " 'plz_1_1',\n",
    " 'openrate_zeitbrief_3m',\n",
    " 'openrate_produktnews_1m',\n",
    " 'openrate_3m',\n",
    " 'openrate_1m',\n",
    " 'nl_unsubscribed_6m',\n",
    " 'nl_fdz_organisch',\n",
    " 'metropole',\n",
    " 'cnt_abo_magazin',\n",
    " 'cnt_abo_diezeit_digital',\n",
    " 'cnt_abo',\n",
    " 'clicked_anzahl_bestandskunden_3m',\n",
    " 'aboform_name_Probeabo',\n",
    " 'aboform_name_Negative Option',\n",
    " 'MONTH_DELTA_abo_min']]\n",
    "        \n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_optimization(X,y,balance=None):\n",
    "    \n",
    "    # devide features\n",
    "    categoric_features = list(X.columns[X.dtypes==object])\n",
    "\n",
    "    numeric_features = list(X.columns[X.dtypes != object])\n",
    "\n",
    "    # split train and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state,stratify=y)\n",
    "    \n",
    "    if balance == 'over':\n",
    "        # define oversampling strategy\n",
    "        print('Oversampling')\n",
    "        oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "        X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "    if balance == 'under':\n",
    "        print('Undersampling')\n",
    "        # define undersample strategy\n",
    "        undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "        X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "        \n",
    "    # Hyperparameter grid\n",
    "    param_logreg = {'logreg__penalty':['l1','l2'],\n",
    "                'logreg__C': (range(0, 100, 10)),\n",
    "                'logreg__solver': ['liblinear', 'saga']\n",
    "               }\n",
    "\n",
    "    \n",
    "    models={\n",
    "        'logreg': LogisticRegression(random_state=random_state,n_jobs=-1) \n",
    "        }  \n",
    "    \n",
    "    # create preprocessors\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer_num', SimpleImputer(strategy='median')),\n",
    "        ('scaler', MinMaxScaler())\n",
    "        #('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer_cat', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categoric_features)\n",
    "        ])\n",
    "\n",
    "    model_results = pd.DataFrame(columns=['model','acc_train','acc_test','f1_train','f1_test','recall_train','recall_test','precision_train','precision_test'])\n",
    "    \n",
    "    \n",
    "    # process pipeline for every model\n",
    "    for model in models.items():\n",
    "        \n",
    "        print(model[0])\n",
    "        pipe = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                               (model[0], model[1])\n",
    "                               ])\n",
    "\n",
    "        grid_logreg = RandomizedSearchCV(pipe, param_logreg, cv=3, scoring='recall', \n",
    "                           verbose=5, n_jobs=-1, n_iter = 100)#, refit='f1')\n",
    "        # fit model\n",
    "        grid_logreg.fit(X_train, y_train)\n",
    "        \n",
    "        # Show best parameters\n",
    "        print('Best score:\\n{:.2f}'.format(grid_logreg.best_score_))\n",
    "        print(\"Best parameters:\\n{}\".format(grid_logreg.best_params_))\n",
    "        \n",
    "        # Save best model as best_model\n",
    "        best_model = grid_logreg.best_estimator_\n",
    "        \n",
    "        #predict results\n",
    "        y_train_pred = grid_logreg.predict(X_train)\n",
    "       \n",
    "\n",
    "        y_test_pred = grid_logreg.predict(X_test)\n",
    "        \n",
    "        results = train_predict(model[0],y_train, y_test, y_train_pred, y_test_pred)\n",
    "        \n",
    "        model_results = pd.concat([model_results, pd.DataFrame(results,index=[0])])\n",
    "        # print results\n",
    "        \n",
    "        print(\"\\nConfusion matrix on test\")\n",
    "        print(confusion_matrix(y_test, y_test_pred))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampling\n",
      "logreg\n",
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:   50.9s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.70\n",
      "Best parameters:\n",
      "{'logreg__solver': 'liblinear', 'logreg__penalty': 'l2', 'logreg__C': 10}\n",
      "\n",
      "Confusion matrix on test\n",
      "[[21202 10968]\n",
      " [ 4305  9690]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RandomizedSearch_logreg = pipeline_optimization(X,y,balance='under')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>fbeta_train</th>\n",
       "      <th>fbeta_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.681362</td>\n",
       "      <td>0.669165</td>\n",
       "      <td>0.686903</td>\n",
       "      <td>0.559259</td>\n",
       "      <td>0.699059</td>\n",
       "      <td>0.69239</td>\n",
       "      <td>0.675163</td>\n",
       "      <td>0.469068</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  acc_train  acc_test  f1_train   f1_test  recall_train  recall_test  \\\n",
       "0  logreg   0.681362  0.669165  0.686903  0.559259      0.699059      0.69239   \n",
       "\n",
       "   precision_train  precision_test  fbeta_train  fbeta_test  \n",
       "0         0.675163        0.469068         0.68         0.7  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomizedSearch_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The Random Grid Search resulted in a result of __recall: 0.69__, __f1: 0.56__ and a __precision: 0.67__. Recall and precision are significant improvements to the first results of __recall: 0.48__, __f1: 0.58__ and a __precision: 0.74__ from the not tuend and unengineered baseline model. However the f1 score declined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
